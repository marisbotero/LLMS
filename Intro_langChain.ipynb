{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLXAdKS53ZD9rppybi8PPl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marisbotero/ML/blob/master/Intro_langChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalar librerías principales y configuración de API Key de OpenAI"
      ],
      "metadata": {
        "id": "EumUAIbOS6eT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4_PPiDl6Kq9G"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain pypdf openai chromadb tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = getpass('Enter the secret value: ')\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnJtp-tNPEZr",
        "outputId": "1e39146c-1ff9-4de4-ddc3-44eb9d779ac4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the secret value: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de documents"
      ],
      "metadata": {
        "id": "s8wUOhnmS5We"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "urls = [\n",
        "    'https://arxiv.org/pdf/2306.06031v1.pdf',\n",
        "    'https://arxiv.org/pdf/2306.12156v1.pdf',\n",
        "    'https://arxiv.org/pdf/2306.14289v1.pdf',\n",
        "    'https://arxiv.org/pdf/2305.10973v1.pdf',\n",
        "    'https://arxiv.org/pdf/2306.13643v1.pdf'\n",
        "]\n",
        "\n",
        "ml_papers = []\n",
        "\n",
        "for i, url in enumerate(urls):\n",
        "    response = requests.get(url)\n",
        "    filename = f'paper{i+1}.pdf'\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "        print(f'Descargado {filename}')\n",
        "\n",
        "        loader = PyPDFLoader(filename)\n",
        "        data = loader.load()\n",
        "        ml_papers.extend(data)\n",
        "\n",
        "# Utiliza la lista ml_papers para acceder a los elementos de todos los documentos descargados\n",
        "print('Contenido de ml_papers:')\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8J8OCMITCG8",
        "outputId": "00d74edd-8394-4783-e608-c0f5daa0d6d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargado paper1.pdf\n",
            "Descargado paper2.pdf\n",
            "Descargado paper3.pdf\n",
            "Descargado paper4.pdf\n",
            "Descargado paper5.pdf\n",
            "Contenido de ml_papers:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(ml_papers), len(ml_papers), ml_papers[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc_mu2GXTJ2E",
        "outputId": "ba112f54-bc46-43ad-de0b-60fd01ff1141"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list,\n",
              " 57,\n",
              " Document(page_content='Figure 1: FinGPT Framework.\\n4.1 Data Sources\\nThe first stage of the FinGPT pipeline involves the collec-\\ntion of extensive financial data from a wide array of online\\nsources. These include, but are not limited to:\\n•Financial news: Websites such as Reuters, CNBC, Yahoo\\nFinance, among others, are rich sources of financial news\\nand market updates. These sites provide valuable informa-\\ntion on market trends, company earnings, macroeconomic\\nindicators, and other financial events.\\n•Social media : Platforms such as Twitter, Facebook, Red-\\ndit, Weibo, and others, offer a wealth of information in\\nterms of public sentiment, trending topics, and immediate\\nreactions to financial news and events.\\n•Filings : Websites of financial regulatory authorities, such\\nas the SEC in the United States, offer access to company\\nfilings. These filings include annual reports, quarterly earn-\\nings, insider trading reports, and other important company-\\nspecific information. Official websites of stock exchanges\\n(NYSE, NASDAQ, Shanghai Stock Exchange, etc.) pro-\\nvide crucial data on stock prices, trading volumes, company\\nlistings, historical data, and other related information.\\n•Trends : Websites like Seeking Alpha, Google Trends, and\\nother finance-focused blogs and forums provide access to\\nanalysts’ opinions, market predictions, the movement of\\nspecific securities or market segments and investment ad-\\nvice.•Academic datasets : Research-based datasets that offer cu-\\nrated and verified information for sophisticated financial\\nanalysis.\\nTo harness the wealth of information from these diverse\\nsources, FinGPT incorporates data acquisition tools capable\\nof scraping structured and unstructured data, including APIs,\\nweb scraping tools, and direct database access where avail-\\nable. Moreover, the system is designed to respect the terms\\nof service of these platforms, ensuring data collection is ethi-\\ncal and legal.\\nData APIs : In the FinGPT framework, APIs are used not\\nonly for initial data collection but also for real-time data up-\\ndates, ensuring the model is trained on the most current data.\\nAdditionally, error handling and rate-limiting strategies are\\nimplemented to respect API usage limits and avoid disrup-\\ntions in the data flow.\\n4.2 Real-Time Data Engineering Pipeline for\\nFinancial NLP\\nFinancial markets operate in real-time and are highly sensi-\\ntive to news and sentiment. Prices of securities can change\\nrapidly in response to new information, and delays in pro-\\ncessing that information can result in missed opportunities or\\nincreased risk. As a result, real-time processing is essential in\\nfinancial NLP.\\nThe primary challenge with a real-time NLP pipeline is\\nmanaging and processing the continuous inflow of data ef-\\nficiently. The first step in the pipeline is to set up a system to', metadata={'source': 'paper1.pdf', 'page': 3}))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split de documents"
      ],
      "metadata": {
        "id": "8RTyGXQlTjLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1500,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len\n",
        "    )\n",
        "\n",
        "documents = text_splitter.split_documents(ml_papers)"
      ],
      "metadata": {
        "id": "c28suyrOXNrb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents), documents[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5O_UDFPXQ7Y",
        "outputId": "c0c77306-69c6-467d-8639-21307d5e543f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(211,\n",
              " Document(page_content='highly volatile, changing rapidly in response to news events\\nor market movements.\\nTrends , often observable through websites like Seeking\\nAlpha, Google Trends, and other finance-oriented blogs and\\nforums, offer critical insights into market movements and in-\\nvestment strategies. They feature:\\n•Analyst perspectives: These platforms provide access to\\nmarket predictions and investment advice from seasoned\\nfinancial analysts and experts.\\n•Market sentiment: The discourse on these platforms can\\nreflect the collective sentiment about specific securities,\\nsectors, or the overall market, providing valuable insights\\ninto the prevailing market mood.\\n•Broad coverage: Trends data spans diverse securities and\\nmarket segments, offering comprehensive market coverage.\\nEach of these data sources provides unique insights into\\nthe financial world. By integrating these diverse data types,\\nfinancial language models like FinGPT can facilitate a com-\\nprehensive understanding of financial markets and enable ef-\\nfective financial decision-making.\\n3.2 Challenges in Handling Financial Data\\nWe summarize three major challenges for handling financial\\ndata as follows:\\n•High temporal sensitivity : Financial data are character-\\nized by their time-sensitive nature. Market-moving news or\\nupdates, once released, provide a narrow window of oppor-\\ntunity for investors to maximize their alpha (the measure of\\nan investment’s relative return).•High dynamism : The financial landscape is perpetually', metadata={'source': 'paper1.pdf', 'page': 2}))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings e ingesta a base de datos vectorial"
      ],
      "metadata": {
        "id": "zs8_DnCKXXgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={\"k\": 3}\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "987Dr-j6XUvk",
        "outputId": "c98a33e9-5b4d-4b12-dcfd-bdf613377642"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos de chat y cadenas para consulta de información"
      ],
      "metadata": {
        "id": "S5YKo_xBXrf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    model_name='gpt-3.5-turbo',\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=chat,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ekbsINeXs5l",
        "outputId": "895d6b6d-c690-49b4-b2b6-b43987250c84"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"qué es fingpt?\"\n",
        "qa_chain.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "3MhgRR3yXvfF",
        "outputId": "f64ae6fb-7545-4fa4-bcf2-e3c1837d5a1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FinGPT es un modelo de lenguaje de inteligencia artificial diseñado específicamente para aplicaciones financieras. Es un modelo de lenguaje de gran escala que utiliza técnicas de aprendizaje automático para comprender y generar texto relacionado con el ámbito financiero. FinGPT se centra en la curación y procesamiento de datos financieros de alta calidad y ofrece una amplia cobertura del mercado financiero. Además, FinGPT es un proyecto de código abierto y tiene como objetivo fomentar la innovación y desbloquear nuevas oportunidades en el campo de las finanzas abiertas.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"qué hace complicado entrenar un modelo como el fingpt?\"\n",
        "qa_chain.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "ilF58e-uXzEu",
        "outputId": "ca34dabc-9a49-4044-b393-85ab9d2732ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Entrenar un modelo como FinGPT puede ser complicado por varias razones:\\n\\n1. Requisitos computacionales intensivos: Modelos como BloombergGPT requieren una gran cantidad de recursos computacionales, como horas de GPU y costos asociados. Esto puede hacer que el entrenamiento sea costoso y lento.\\n\\n2. Costo financiero: El entrenamiento de modelos como BloombergGPT puede ser extremadamente costoso, llegando a millones de dólares. Esto limita su accesibilidad y hace que sea menos viable para muchas organizaciones.\\n\\n3. Actualizaciones y adaptabilidad: En el dominio financiero, es crucial tener modelos actualizados y adaptables debido a la naturaleza dinámica del mercado. Entrenar un modelo desde cero cada vez que se requiere una actualización puede ser ineficiente y llevar mucho tiempo.\\n\\n4. Personalización y servicios financieros personalizados: Existe una creciente demanda de servicios financieros personalizados. Entrenar modelos desde cero para cada usuario o caso individual puede ser impracticable. Por lo tanto, es más eficiente y efectivo adaptar modelos preexistentes a través de la técnica de ajuste fino (fine-tuning).\\n\\nEn resumen, entrenar modelos como FinGPT desde cero puede ser costoso, lento y menos adaptable a las necesidades individuales. Por lo tanto, el ajuste fino de modelos preexistentes ofrece una solución más accesible, flexible y rentable para el modelado del lenguaje financiero.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mrdcZ0taYQnQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}